{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2 Summative Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "For today's section, we're going to work on a single big lab to apply everything we've learned in Module 2!\n",
    "\n",
    "## About This Lab\n",
    "\n",
    "A quick note before getting started--this lab isn't like other labs you seen so far. This lab is meant to take ~8 hours to complete, so it's much longer and more challenging that the average labs you've seen so far. If you feel like this lab is challenging or that you might be struggling a bit, don't fret--that's by design! With everything we've learned about Web Scraping, APIs, and Databases, the best way to test our knowledge of it is to build something substantial! \n",
    "\n",
    "## The Project\n",
    "\n",
    "In this lab, we're going to make use of everything we've learned about APIs, databases, and Object-Oriented Programming to **_Extract, Transform, and Load_** (or **_ETL_**, for short) some data from a SQL database into a MongoDB Database. \n",
    "\n",
    "You'll find a database containing information about soccer teams and the matches they've played in the file `database.sqlite`. For this project, our goal is to get the data we think is important from this SQL database, do some calculations and data transformation, and then store everything in a MongoDB database. \n",
    "\n",
    "Let's get into the specifics of this project.\n",
    "\n",
    "### The Goal\n",
    "\n",
    "Start by examining the data dictionary for the SQL database we'll be working with, which comes from this [kaggle page](https://www.kaggle.com/laudanum/footballdelphi).  Familiarize yourself with the tables it contains, and what each column means. We'll be using this database to get data on each soccer team, calculate some summary statistics, and then store each in a MongoDB database. \n",
    "\n",
    "Upon completion of this lab, each unique team in this dataset should have a record in the MongoDB instance containing the following information:\n",
    "\n",
    "* The name of the team\n",
    "* The total number of goals scored by the team during the 2011 season\n",
    "* The total number of wins the team earned during the 2011 season\n",
    "* A histogram visualization of the team's wins and losses for the 2011 season (store the visualization directly)\n",
    "* The team's win percentage on days where it was raining during games in the 2011 season. \n",
    "\n",
    "#### Getting the Weather Data\n",
    "\n",
    "Note that for this last calculation, you'll need to figure out if it was raining or not during the game. The database itself does not contain this information, but it does contain the date on which the game was played. For this, you'll need to use the [DarkSky API](https://darksky.net/dev) to get the historical weather data for that day. Note that each game is played in a different location, and this information is not contained in our SQL database. However, the teams in this database are largely german, so go ahead and just use the weather in Berlin, Germany as a proxy for this information. If it was raining in Berlin on the day the game was played, count that as rain game--**_you do not need to try and figure out the actual weather at each game's location, because we don't have that information!_**\n",
    "\n",
    "#### NOTE: The DarkSky API is limited to 1000 free API calls a day, so be sure to test your model on very small samples. Otherwise, you'll hit the rate limit!\n",
    "\n",
    "## Project Architecture\n",
    "\n",
    "Unlike previous labs, this lab is more open-ended, and will require you to make design decisions and plan out your strategy for building a system with this many working parts. However, **_using Object-Oriented Programming is a requirement for this project--you must create at least 2 separate, well structured classes in your solution!_** Although it may seem easier to \"just start coding\", this is a classic beginner's mistake. Instead, think about separating out the different functionalities you'll need to reach your goal, and then build classes to handle each. For instance, at minimum, you'll need to:\n",
    "\n",
    "* Query the SQL database\n",
    "* Calculate summary statistics\n",
    "* Get the weather data from the DarkSky API\n",
    "* Load the data into MongoDB\n",
    "\n",
    "We **_strongly recommend_** you consider creating separate classes for handling at least some of these of these tasks.  Be sure to plan the inputs, outputs, and methods for each class before you begin coding! \n",
    "\n",
    "**_NOTE:_** We have provided some empty classes below. You are welcome to delete them and use a different architecture for this project if you so choose.  You do not have to use each of them, they are just there to give you an idea of what you could sorts of classes you may want to consider using.\n",
    "\n",
    "### Rapid Prototyping and Refactoring\n",
    "\n",
    "It's totally okay to try to get a task working without using OOP. For instance, when experimenting with the DarkSky API for getting historical weather data, it makes sense to just write the code in the cells and rapidly iterate until you get it all working. However, once you get it working, you're not done--you should then **_Refactor_** your code into functions or classes to make your code more modular, reusable, understandable, and maintainable! \n",
    "\n",
    "In short--do what you need to do to get each separate piece of functionality working, and then refactor it into a class after you've figured it out!\n",
    "\n",
    "### Some Final Advice\n",
    "\n",
    "You haven't built anything this big or complex thus far, so you may not yet fully realize how much trial and error goes into it. If your code keeps breaking, resist the urge to get frustrated, and just keep working. Software development is an iterative process!  No one writes perfect code that works the first time for something this involved. You're going to run into _a lot_ of small errors in this project, right up until the point where it just works, and then you're done! However, you can reduce these errors by planning out your code, and thinking about how all of the pieces fit together before you begin coding. Once you have some basic understanding of how it all will work, then you'll know what you need to build, and then all that is left is to build it!\n",
    "\n",
    "In short:\n",
    "\n",
    "* Plan ahead--you'll thank yourself later!\n",
    "* Errors and broken code aren't bad, they're normal. \n",
    "* Keep working, and stay confident--you can do this!\n",
    "\n",
    "Good luck--we look forward to seeing your completed project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import PIL\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import apikey as api\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting our database for use in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('database.sqlite')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving the data into Pandas so that we can calculate summary statistics and make visualizations\n",
    "After reviewing the different tables in the kaggle database, we found that we could get all the information we needed was contained in the Matches table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"\"\"SELECT * FROM Matches WHERE Season = 2011\"\"\")\n",
    "matches = pd.DataFrame(c.fetchall())\n",
    "matches.columns = [x[0] for x in c.description]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We started by creating a MatchInfo Class\n",
    "This class contained the functions necessary to find total goals, total games won, and total games lost by the teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchInfo:\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def total_goals(self):\n",
    "        \n",
    "        \"\"\"Takes in our dataframe in question and outputs a dataframe \n",
    "        with the total number of goals for each team.\"\"\"\n",
    "        \n",
    "        home_goals = self.df.groupby('HomeTeam').sum()[['FTHG']]\n",
    "        away_goals = self.df.groupby('AwayTeam').sum()[['FTAG']]\n",
    "        total = home_goals.join(away_goals, how = 'inner')\n",
    "        total['totals'] = total.FTHG + total.FTAG\n",
    "        total_goals = total[['totals']] \n",
    "        total_goals.reset_index(inplace = True)\n",
    "        total_goals.columns = ['TeamName', 'total_goals_scored']\n",
    "        return total_goals\n",
    "    \n",
    "    def team_names(self):\n",
    "        \n",
    "        \"\"\"Takes in our dataframe in question and \n",
    "        outputs a list of all our team names.\"\"\"\n",
    "        \n",
    "        return list(self.df['HomeTeam'].unique())\n",
    "\n",
    "    def total_won(self):\n",
    "        \n",
    "        \"\"\"Takes in our dataframe in question and outputs a \n",
    "        dataframe of the total games won per team.\"\"\"\n",
    "        \n",
    "        self.df['home_won'] = self.df.FTR.apply(lambda x: 1 if x == 'H' else 0)\n",
    "        self.df['away_won'] = self.df.FTR.apply(lambda x: 1 if x == 'A' else 0)\n",
    "        home_won = self.df.groupby('HomeTeam').sum()[['home_won']]\n",
    "        away_won = self.df.groupby('AwayTeam').sum()[['away_won']]\n",
    "        total_won = home_won.join(away_won, how = 'inner')\n",
    "        total_won['total_won'] = total_won.home_won + total_won.away_won\n",
    "        total_won = total_won[['total_won']]\n",
    "        total_won.reset_index(inplace = True)\n",
    "        total_won.columns = ['TeamName', 'total_games_won']\n",
    "        return total_won\n",
    "    \n",
    "    def total_lost(self):\n",
    "        \n",
    "        \"\"\"Takes in our dataframe in question and outputs a \n",
    "        dataframe of the total games lost per team.\"\"\"\n",
    "        \n",
    "        self.df['home_lost'] = self.df.FTR.apply(lambda x: 1 if x == 'A' else 0)\n",
    "        self.df['away_lost'] = self.df.FTR.apply(lambda x: 1 if x == 'H' else 0)\n",
    "        home_lost = self.df.groupby('HomeTeam').sum()[['home_lost']]\n",
    "        away_lost = self.df.groupby('AwayTeam').sum()[['away_lost']]\n",
    "        total_lost = home_lost.join(away_lost, how = 'inner')\n",
    "        total_lost['total_lost'] = total_lost.home_lost + total_lost.away_lost\n",
    "        total_lost = total_lost[['total_lost']]\n",
    "        total_lost.reset_index(inplace = True)\n",
    "        total_lost.columns = ['TeamName', 'total_games_lost']\n",
    "        return total_lost\n",
    "    \n",
    "    \n",
    "match_info = MatchInfo(matches)\n",
    "# Instantiating the dataframe to use when calling functions from our class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming dataframe for visualization\n",
    "Here we transformed our dataframe to a dictionary to be able to loop through and plot individual graphs of wins and losses per team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost = match_info.total_lost()\n",
    "won = match_info.total_won()\n",
    "won_lost = won.merge(lost, how = 'inner', on = 'TeamName')\n",
    "lost['type'] = 'lost'\n",
    "lost.rename(columns = {'total_games_lost': 'points'}, inplace = True)\n",
    "won['type'] = 'won'\n",
    "won.rename(columns = {'total_games_won': 'points'}, inplace = True)\n",
    "concat = pd.concat([won, lost], axis = 0)\n",
    "concat.sort_values(by = 'TeamName', inplace = True)\n",
    "concat.set_index(['TeamName', 'type'], inplace = True)\n",
    "unstacked = concat.unstack()\n",
    "unstacked_dict = unstacked.to_dict('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We created a class to build and directly store graphs as images into a directory\n",
    "To more easily move our data into MongoDB, we directly stored our images into a new directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildGraph:\n",
    "    \n",
    "    def __init__(self, dictionary):\n",
    "        self.dictionary = dictionary\n",
    "\n",
    "    def build_graph(self):\n",
    "        \n",
    "        \"\"\"This function takes in a dictionary and outputs a graph for each \n",
    "        team as well as stats on how many wins and losses the team had in the 2011 season. \n",
    "        It also stores each graph as an individual image to the new directory 'Team_Graphs'\n",
    "        \"\"\"\n",
    "        os.makedirs('Team_Graphs')\n",
    "        for team in self.dictionary:\n",
    "            plt.bar(x = [0, 1], height = [self.dictionary[team]['points', 'lost'], \n",
    "                              self.dictionary[team]['points', 'won']], tick_label = ['Won', 'Lost'])\n",
    "            plt.title(team)\n",
    "            plt.xlabel('Outcomes')\n",
    "            plt.ylabel('Number of games')\n",
    "            plt.savefig(\"Team_Graphs/{}.png\".format(team))\n",
    "            plt.close()\n",
    "            \n",
    "\n",
    "to_graph = BuildGraph(unstacked_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming our images into a dictionary of arrays\n",
    "To be able to store our images into MongoDB, we needed to turn our images of our graphs into arrays. The following function uses Python Imaging Library (PIL) to open each image and numpy to change the format to array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = os.listdir('Team_Graphs')\n",
    "\n",
    "fig_dictionary = {}\n",
    "for fig in figs:\n",
    "    img = PIL.Image.open('team_graphs/{}'.format(fig)). convert('L')\n",
    "    array = numpy.array(img)\n",
    "    fig_dictionary.update({fig: array})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the dataframe for use with the Dark Sky API\n",
    "\n",
    "To be able to use the dark sky api, we found it easier to convert our dates to unix time.  We created a class to convert our dates.  Then we created a class to fetch the weather data for our dates and return a dictionary of with the weather matched to matchID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class weather_prepare:\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "\n",
    "    def prepare_dataframe_for_weather(self):\n",
    "        \n",
    "        \"\"\"\"We set our date and time to Unix timecode so as to \n",
    "            more easily access the date information from DarkSky\"\"\"\"\n",
    "        \n",
    "        data.set_index('Match_ID', inplace = True)\n",
    "        data['Date'] = pd.to_datetime(data['Date'])\n",
    "        data['Unix_Date'] = (data['Date'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "\n",
    "unix = weather_prepare(data)\n",
    "\n",
    "unix.prepare_dataframe_for_weather()\n",
    "\n",
    "dates = data['Unix_Date']\n",
    "\n",
    "\n",
    "class weather_scrape:\n",
    "    def __init__(self):\n",
    "        self.url = 'https://api.darksky.net/forecast'\n",
    "        self.key = api.API_Key4\n",
    "        self.latitude = \"52.5200\"\n",
    "        self.longitude = \"13.4050\"\n",
    "        self.exclude = 'currently,flags,minutely,hourly,alerts'\n",
    "        self.df = data\n",
    "        self.dates = dates\n",
    "\n",
    "    def api_call(self):\n",
    "        \"\"\"\"Using our API, we are getting weather condition information for each date \n",
    "            and storing this in a dictionary for future use\n",
    "        \"\"\"\"\n",
    "        weather_dict = {}\n",
    "        for date in self.dates:\n",
    "            good_url = \"{}/{}/{},{},{}?exclude={}\".format(self.url,self.key,self.latitude, \n",
    "                                                          self.longitude, date, self.exclude)   \n",
    "            response = requests.get(good_url)\n",
    "            print(response)\n",
    "            weather_data = response.json()['daily']['data'][0]['icon']\n",
    "            weather_dict.update({date: weather_data})\n",
    "        return weather_dict\n",
    "\n",
    "weather_data = weather_scrape()\n",
    "\n",
    "weather = weather_data.api_call()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then created a fucntion to take the weather dictionary and convert it into a dataframe to be joined with the team information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_weather_to_df(weather):\n",
    "    \"\"\"\"This function takes in our dictionary of weather information and \n",
    "        outputs a new dataframe with the weather conditions which is then \n",
    "        merged to the main dataframe\n",
    "    \"\"\"\"\n",
    "    wdf = pd.DataFrame(weather, index = ['weather'])\n",
    "    wdf2 = pd.DataFrame.transpose(wdf)\n",
    "    wdf2 = wdf2.reset_index()\n",
    "    wdf2.rename(columns={'index': 'Unix_Date'}, inplace=True)\n",
    "    dfw = pd.merge(data, wdf2, how = 'left', on = 'Unix_Date')\n",
    "    return dfw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then transformed the weather dataframe to find out the percentage of games played when it rained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = adding_weather_to_df(weather)\n",
    "final['weather'] = final.weather.apply(lambda x: 1 if x == 'rain' else 0)\n",
    "final['all_weather'] = final.weather.apply(lambda x: 1)\n",
    "\n",
    "# We created 2 new columns: 1 that allows us to sum the number of times it rained and 1 that allows us to sum \n",
    "# the total number of games\n",
    "\n",
    "home_rain = final.groupby('HomeTeam').sum()[['weather']]\n",
    "home_all = final.groupby('HomeTeam').sum()[['all_weather']]\n",
    "away_rain = final.groupby('AwayTeam').sum()[['weather']]\n",
    "away_all = final.groupby('AwayTeam').sum()[['all_weather']]\n",
    "\n",
    "# We then summed these values to find the proportion of days when it rained\n",
    "\n",
    "total_rain = home_rain.weather + away_rain.weather\n",
    "total_weather = home_all.all_weather +away_all.all_weather\n",
    "avg_weather = total_rain/total_weather*100\n",
    "\n",
    "# We found the average number of times it rained\n",
    "\n",
    "total_wins = match_info.total_won()\n",
    "total_goal = match_info.total_goals()\n",
    "games = total_wins.merge(total_goal, how = 'inner', on = 'TeamName')\n",
    "dw = pd.DataFrame(avg_weather)\n",
    "dw.reset_index(inplace = True)\n",
    "dw.rename(columns = {0: 'rain_percent'}, inplace = True)\n",
    "FINAL = pd.concat([games, dw], axis = 1)\n",
    "FINAL.drop('HomeTeam', axis = 1, inplace = True)\n",
    "\n",
    "# We merged our dataframes so as to see all of our data together and provide for easier MongoDB insertion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting data into MongoDB\n",
    "We have not got to test our class to insert our data into the mongodb but this was our approach to do that eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mongo_maker:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.myclient = pymongo.MongoClient('mongodb://localhost:27017')\n",
    "        self.mydb = self.myclient['2011_season_stats']\n",
    "        self.mycollection = self.mydb['2011_season_stats']\n",
    "    \n",
    "    def format_data(self, name, totalgoals, totalwins, bar_graph, rain_wins):\n",
    "        data = {\"team_name\": name,\n",
    "               \"total_goals\": totalgoals,\n",
    "               \"total_wins\": totalwins,\n",
    "               \"win_loss_graph\": bar_graph,\n",
    "               \"rain_wins\": rain_wins}\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def insert_record(self, record):\n",
    "        return self.mycollection.insert_one(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this lab, we dug deep and used everything we've learned so far about python programming, databases, HTTP requests and API calls to ETL data from a SQL database into a MongoDB instance!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
